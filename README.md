# ğŸ• ASR-Doge: Parameter-Efficient Speech Recognition with SmallDoge

<p align="center">
  <img src="https://img.shields.io/badge/WER-4.70%25-brightgreen" alt="WER">
  <img src="https://img.shields.io/badge/CER-2.75%25-brightgreen" alt="CER">
  <img src="https://img.shields.io/badge/RTF-0.91x-blue" alt="Real-Time Factor">
  <img src="https://img.shields.io/badge/Trainable_Params-0.05%25-orange" alt="Trainable Parameters">
  <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License">
</p>

**ASR-Doge** is a parameter-efficient automatic speech recognition (ASR) model that combines IBM's Granite Speech encoder with SmallDoge language model through a lightweight MLP adapter. This project demonstrates that competitive ASR performance can be achieved by training only **0.05%** of the total model parameters.

## ğŸ¯ Key Results

| Metric | Score |
|--------|-------|
| **Word Error Rate (WER)** | 4.70% |
| **Character Error Rate (CER)** | 2.75% |
| **Perfect Match Rate** | 46.0% |
| **Real-Time Factor** | 0.91x (faster than real-time!) |
| **Trainable Parameters** | 1.57M / 3.36B (0.05%) |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ASR-Doge Architecture                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Audio Input (16kHz)                                         â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   Speech Encoder (FROZEN)          â”‚                      â”‚
â”‚  â”‚   IBM Granite Speech 3.3-2B        â”‚                      â”‚
â”‚  â”‚   Parameters: ~3.04B               â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                   â”‚ [B, T, 2048]                              â”‚
â”‚                   â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   MLP Adapter (TRAINABLE)          â”‚                      â”‚
â”‚  â”‚   2048 â†’ 512 â†’ 1024                â”‚                      â”‚
â”‚  â”‚   Parameters: 1.57M                â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                   â”‚ [B, T, 1024]                              â”‚
â”‚                   â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚   Language Model (TRAINABLE)       â”‚                      â”‚
â”‚  â”‚   SmallDoge-320M                   â”‚                      â”‚
â”‚  â”‚   Parameters: 320M                 â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                   â”‚                                           â”‚
â”‚                   â–¼                                           â”‚
â”‚            Text Transcription                                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Requirements

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (for GPU training)
- 24GB+ VRAM (40GB recommended)

### Setup

```bash
# Clone the repository
git clone https://github.com/SmallDoge/asr-doge.git
cd asr-doge

# Create conda environment
conda create -n asr-doge python=3.10
conda activate asr-doge

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

```txt
# requirements.txt
torch>=2.0.0
torchaudio>=2.0.0
transformers>=4.35.0
jiwer>=3.0.0
wandb>=0.15.0
tqdm>=4.65.0
numpy>=1.24.0
```

## ğŸš€ Quick Start

### 1. Download Dataset

```bash
# Download LibriSpeech (train-clean-100, dev-clean, test-clean)
python scripts/download_librispeech.py --output_dir ./data
```

### 2. Process Dataset

```bash
python src/data/data_processor.py \
    --dataset librispeech \
    --data_dir ./data \
    --output_dir ./processed \
    --train_split train-clean-100 \
    --dev_split dev-clean \
    --test_split test-clean
```

### 3. Train Model

```bash
python src/training/train.py \
    --data_dir ./processed \
    --output_dir ./checkpoints \
    --batch_size 16 \
    --learning_rate 2e-3 \
    --epochs 1 \
    --patience 2 \
    --wandb_project asr-doge
```

### 4. Run Benchmark

```bash
python src/benchmark/benchmark.py \
    --checkpoint_dir ./checkpoints/best \
    --data_dir ./processed \
    --output_dir ./benchmark_results \
    --max_samples 200
```

## ğŸ“Š Reproduce Our Results

To reproduce the exact results from our paper/TCC:

```bash
# Full training and evaluation pipeline
./scripts/reproduce.sh
```

Or step by step:

```bash
# 1. Process LibriSpeech data
python src/data/data_processor.py \
    --data_dir /path/to/librispeech \
    --output_dir ./processed

# 2. Train with our exact hyperparameters
python src/training/train.py \
    --data_dir ./processed \
    --output_dir ./checkpoints \
    --batch_size 16 \
    --learning_rate 0.002 \
    --epochs 1 \
    --patience 2 \
    --eval_steps 100 \
    --speech_encoder ibm-granite/granite-speech-3.3-2b \
    --language_model SmallDoge/Doge-320M-Checkpoint

# 3. Run comprehensive benchmark
python src/benchmark/benchmark.py \
    --checkpoint_dir ./checkpoints/best \
    --data_dir ./processed \
    --max_samples 200 \
    --num_speed_runs 10
```

## ğŸ“ Project Structure

```
asr-doge/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ LICENSE                       # Apache 2.0 License
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_processor.py     # Dataset processing utilities
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train.py              # Training script and model definition
â”‚   â”œâ”€â”€ benchmark/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ benchmark.py          # Comprehensive benchmark script
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ configuration_singer_doge.py
â”‚   â”‚   â””â”€â”€ modeling_singer_doge.py
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ conv.py
â”‚       â”œâ”€â”€ conv_norm.py
â”‚       â”œâ”€â”€ ltsm.py
â”‚       â””â”€â”€ nae.py                # Neural Audio Encoder (SEANet)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_librispeech.py   # Dataset download script
â”‚   â””â”€â”€ reproduce.sh              # Full reproduction script
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml              # Default configuration
â””â”€â”€ examples/
    â””â”€â”€ inference.py              # Example inference script
```

## ğŸ”§ Configuration

### Model Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `speech_encoder` | `ibm-granite/granite-speech-3.3-2b` | Pre-trained speech encoder |
| `language_model` | `SmallDoge/Doge-320M-Checkpoint` | Language model for text generation |
| `adapter_input_dim` | 2048 | Input dimension from speech encoder |
| `adapter_hidden_dim` | 512 | Hidden dimension in MLP adapter |
| `adapter_output_dim` | 1024 | Output dimension matching LM |

### Training Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `batch_size` | 16 | Training batch size |
| `learning_rate` | 2e-3 | Peak learning rate |
| `epochs` | 1 | Number of training epochs |
| `patience` | 2 | Early stopping patience |
| `eval_steps` | 100 | Steps between evaluations |

## ğŸ“ˆ Training Curves

Our model converges quickly due to the pre-trained components:

- **Training Loss**: 3.5 â†’ 0.24 (over ~1,800 steps)
- **Validation CER**: Improves steadily with early stopping at patience=2

## ğŸ§ª Evaluation

### Accuracy Metrics

```python
from src.benchmark import ASRDogeBenchmark, BenchmarkConfig

config = BenchmarkConfig(checkpoint_dir="./checkpoints/best")
benchmark = ASRDogeBenchmark(config)
benchmark.load_models()

# Run on test set
result = benchmark.run_full_benchmark(test_samples)
print(f"WER: {result.accuracy.wer:.2%}")
print(f"CER: {result.accuracy.cer:.2%}")
```

### Speed Benchmark

```python
# Measure inference speed
speed_result = benchmark.benchmark_speed(audio_path)
print(f"Latency: {speed_result['total_latency_ms']:.2f}ms")
print(f"Real-Time Factor: {speed_result['real_time_factor']:.2f}x")
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Areas for Contribution

1. **Model Improvements**: Better adapter architectures, LoRA integration
2. **Dataset Support**: Additional datasets beyond LibriSpeech
3. **Multilingual**: Leverage Granite's multilingual capabilities
4. **Streaming**: Real-time streaming ASR implementation
5. **Quantization**: INT8/INT4 quantization for edge deployment

## ğŸ“œ Citation

If you use ASR-Doge in your research, please cite:

```bibtex
@misc{asrdoge2026,
  title={ASR-Doge: Parameter-Efficient Speech Recognition with SmallDoge},
  author={Julio Hsu and SmallDoge Team},
  year={2026},
  howpublished={\url{https://github.com/SmallDoge/asr-doge}},
}
```

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **SmallDoge Team** for the efficient Doge language model family
- **IBM** for the Granite Speech encoder
- **HuggingFace** for the transformers library
- **LibriSpeech** creators for the benchmark dataset

## ğŸ“¬ Contact

- **GitHub Issues**: For bugs and feature requests
- **Discussions**: For questions and community support
- **Email**: [your-email@example.com]

---

<p align="center">
  Made with â¤ï¸ by the SmallDoge Team
</p>
